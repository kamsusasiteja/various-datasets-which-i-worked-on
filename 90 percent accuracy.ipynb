{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/User/Desktop/datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "d=pd.read_csv(\"DelayedFlights.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                0\n",
       "Year                      0\n",
       "Month                     0\n",
       "DayofMonth                0\n",
       "DayOfWeek                 0\n",
       "DepTime                   0\n",
       "CRSDepTime                0\n",
       "ArrTime                3896\n",
       "CRSArrTime                0\n",
       "UniqueCarrier             0\n",
       "FlightNum                 0\n",
       "TailNum                   4\n",
       "ActualElapsedTime      3896\n",
       "CRSElapsedTime          157\n",
       "AirTime                3896\n",
       "ArrDelay               3896\n",
       "DepDelay                  0\n",
       "Origin                    0\n",
       "Dest                      0\n",
       "Distance                  0\n",
       "TaxiIn                 3896\n",
       "TaxiOut                   0\n",
       "Cancelled                 0\n",
       "CancellationCode          0\n",
       "Diverted                  0\n",
       "CarrierDelay         362841\n",
       "WeatherDelay         362841\n",
       "NASDelay             362841\n",
       "SecurityDelay        362841\n",
       "LateAircraftDelay    362841\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.apply(lambda x:sum(x.isnull()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=d[np.isfinite(d['ArrDelay'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                0\n",
       "Year                      0\n",
       "Month                     0\n",
       "DayofMonth                0\n",
       "DayOfWeek                 0\n",
       "DepTime                   0\n",
       "CRSDepTime                0\n",
       "ArrTime                   0\n",
       "CRSArrTime                0\n",
       "UniqueCarrier             0\n",
       "FlightNum                 0\n",
       "TailNum                   3\n",
       "ActualElapsedTime         0\n",
       "CRSElapsedTime            0\n",
       "AirTime                   0\n",
       "ArrDelay                  0\n",
       "DepDelay                  0\n",
       "Origin                    0\n",
       "Dest                      0\n",
       "Distance                  0\n",
       "TaxiIn                    0\n",
       "TaxiOut                   0\n",
       "Cancelled                 0\n",
       "CancellationCode          0\n",
       "Diverted                  0\n",
       "CarrierDelay         358945\n",
       "WeatherDelay         358945\n",
       "NASDelay             358945\n",
       "SecurityDelay        358945\n",
       "LateAircraftDelay    358945\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.apply(lambda x:sum(x.isnull()),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           8\n",
       "1          19\n",
       "2           8\n",
       "3          34\n",
       "4          25\n",
       "5          67\n",
       "6           6\n",
       "7          94\n",
       "8           9\n",
       "9          27\n",
       "10          9\n",
       "11         28\n",
       "12         51\n",
       "13         32\n",
       "14         20\n",
       "15          9\n",
       "16         25\n",
       "17         87\n",
       "18         29\n",
       "19         82\n",
       "20         12\n",
       "21         19\n",
       "22         39\n",
       "23         82\n",
       "24         22\n",
       "25         29\n",
       "26         56\n",
       "27         24\n",
       "28          6\n",
       "29          6\n",
       "           ..\n",
       "1048545    10\n",
       "1048546    37\n",
       "1048547    55\n",
       "1048548    45\n",
       "1048549    72\n",
       "1048550     9\n",
       "1048551    19\n",
       "1048552    10\n",
       "1048553    99\n",
       "1048554    10\n",
       "1048555    14\n",
       "1048556    16\n",
       "1048557    20\n",
       "1048558    14\n",
       "1048559    23\n",
       "1048560    23\n",
       "1048561    24\n",
       "1048562    42\n",
       "1048563     8\n",
       "1048564    48\n",
       "1048565    48\n",
       "1048566    10\n",
       "1048567    34\n",
       "1048568    41\n",
       "1048569    42\n",
       "1048570    16\n",
       "1048571    20\n",
       "1048572    20\n",
       "1048573    32\n",
       "1048574    33\n",
       "Name: DepDelay, Length: 1044679, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep=d['DepDelay']\n",
    "dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=d['ArrDelay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          -14.0\n",
       "1            2.0\n",
       "2           14.0\n",
       "3           34.0\n",
       "4           11.0\n",
       "5           57.0\n",
       "6            1.0\n",
       "7           80.0\n",
       "8           11.0\n",
       "9           15.0\n",
       "10         -15.0\n",
       "11          16.0\n",
       "12          37.0\n",
       "13          19.0\n",
       "14           6.0\n",
       "15          -7.0\n",
       "16          14.0\n",
       "17          47.0\n",
       "18           4.0\n",
       "19          64.0\n",
       "20          -4.0\n",
       "21          -5.0\n",
       "22          14.0\n",
       "23          72.0\n",
       "24           5.0\n",
       "25          11.0\n",
       "26          29.0\n",
       "27         -11.0\n",
       "28         -22.0\n",
       "29         -26.0\n",
       "           ...  \n",
       "1048545     -3.0\n",
       "1048546     29.0\n",
       "1048547     40.0\n",
       "1048548     49.0\n",
       "1048549     73.0\n",
       "1048550     -5.0\n",
       "1048551     14.0\n",
       "1048552     -1.0\n",
       "1048553    134.0\n",
       "1048554     17.0\n",
       "1048555      4.0\n",
       "1048556      9.0\n",
       "1048557     32.0\n",
       "1048558     25.0\n",
       "1048559     17.0\n",
       "1048560     35.0\n",
       "1048561      6.0\n",
       "1048562     30.0\n",
       "1048563     -3.0\n",
       "1048564     42.0\n",
       "1048565     48.0\n",
       "1048566     29.0\n",
       "1048567     27.0\n",
       "1048568     39.0\n",
       "1048569     47.0\n",
       "1048570      8.0\n",
       "1048571     12.0\n",
       "1048572      2.0\n",
       "1048573     26.0\n",
       "1048574     18.0\n",
       "Name: ArrDelay, Length: 1044679, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=d['DepDelay']\n",
    "y=d['ArrDelay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.values.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model as lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=lm.LinearRegression()\n",
    "results=model.fit(X_train,y_train)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model 0.9080882845825773\n"
     ]
    }
   ],
   "source": [
    "accuracy=model.score(X_train,y_train)\n",
    "print('Accuracy of the model',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept -1.1990695188404175\n",
      "slope [1.01538144]\n"
     ]
    }
   ],
   "source": [
    "print('intercept',model.intercept_)\n",
    "print('slope',model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 26],\n",
       "       [ 16],\n",
       "       [103],\n",
       "       ...,\n",
       "       [ 18],\n",
       "       [ 10],\n",
       "       [ 18]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=X_test.values.reshape((-1,1))\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted arr delay\n",
      "[ 25.20084787  15.04703349 103.38521859 ...  17.07779636   8.95474486\n",
      "  17.07779636]\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(X_test)\n",
    "print('predicted arr delay',predictions,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.8961565380992855\n"
     ]
    }
   ],
   "source": [
    "y_test=y_test.values.reshape((-1,1))\n",
    "accuracy=model.score(y_test,predictions)\n",
    "print('Accuracy of model:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new tmprature:[[30]], Predicted failurs=[29.26237362]\n"
     ]
    }
   ],
   "source": [
    "# we have completed realizing a model.we shall now check this model on new data points \n",
    "\n",
    "# define new data instance\n",
    "Xnew=[[30]]\n",
    "#make a prediction\n",
    "ynew=model.predict(Xnew)\n",
    "# show the inputs and predicted outputs\n",
    "print('new tmprature:%s, Predicted failurs=%s'%(Xnew,ynew))       # this type of print statement,in python, is adopted from 'c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model valuation for training set:\n",
      "--------------------\n",
      "RMSE is: 16.898548045449015\n",
      "r2 square is: 0.9080882845825774\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "X_train=X_train.reshape(-1,1)\n",
    "y_train_prediction=model.predict(X_train)\n",
    "\n",
    "X_test=X_test.reshape(-1,1)\n",
    "y_test_prediction=model.predict(X_test)\n",
    "\n",
    "#model evaluation for training set\n",
    "import numpy as np\n",
    "rmse_training=(np.sqrt(mean_squared_error(y_train,y_train_prediction)))\n",
    "# for a good model,rmse should b low.\n",
    "r2_training=r2_score(y_train,y_train_prediction)\n",
    "print('model valuation for training set:')\n",
    "print('-'*20)\n",
    "print('RMSE is: {}'.format(rmse_training))     # .format argumnts values are passed into those braces\n",
    "print('r2 square is: {}'.format(r2_training))   #this .format() representation called replacement fields is obtained from c#.net\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model valuation for testing set:\n",
      "--------------------\n",
      "RMSE is: 16.935160566709826\n",
      "r2 square is: 0.9088387547996757\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "rmse_testing=(np.sqrt(mean_squared_error(y_test,y_test_prediction)))\n",
    "# for a good model,rmse should b low.\n",
    "r2_testing=r2_score(y_test,y_test_prediction)\n",
    "print('model valuation for testing set:')\n",
    "print('-'*20)\n",
    "print('RMSE is: {}'.format(rmse_testing))\n",
    "print('r2 square is: {}'.format(r2_testing))\n",
    "print(\"\\n\")\n",
    "\n",
    "#rmse should be low,r sqaure should be high\n",
    "#rmse gives us the variance..so if variance is high,the data relation is inconsistent\n",
    "# check whether training is consistent or not using the first statemnt.check the same with testing.now relate both training and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model valuation for testing set:\n",
      "--------------------\n",
      "RMSE is: 16.935160566709826\n",
      "r2 square is: 0.9088387547996757\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "rmse_testing=(np.sqrt(mean_squared_error(y_test,y_test_prediction)))\n",
    "# for a good model,rmse should b low.\n",
    "r2_testing=r2_score(y_test,y_test_prediction)\n",
    "print('model valuation for testing set:')\n",
    "print('-'*20)\n",
    "print('RMSE is: {}'.format(rmse_testing))\n",
    "print('r2 square is: {}'.format(r2_testing))\n",
    "print(\"\\n\")\n",
    "\n",
    "#rmse should be low,r sqaure should be high\n",
    "#rmse gives us the variance..so if variance is high,the data relation is inconsistent\n",
    "# check whether training is consistent or not using the first statemnt.check the same with testing.now relate both training and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.values.reshape((-1,1))\n",
    "y_prediction=model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
